###############################################################################
#
#  Welcome to Baml! To use this generated code, please run the following:
#
#  $ pip install baml-py
#
###############################################################################

# This file was generated by BAML: please do not edit it. Instead, edit the
# BAML files and re-generate this code.
#
# ruff: noqa: E501,F401
# flake8: noqa: E501,F401
# pylint: disable=unused-import,line-too-long
# fmt: off

file_map = {
    
    "clients.baml": "// Learn more about clients at https://docs.boundaryml.com/docs/snippets/clients/overview\r\n\r\nclient<llm> CustomGPT4o {\r\n  provider openai\r\n  options {\r\n    model \"gpt-4o\"\r\n    api_key env.OPENAI_API_KEY\r\n  }\r\n}\r\n\r\nclient<llm> CustomGPT4oMini {\r\n  provider openai\r\n  retry_policy Exponential\r\n  options {\r\n    model \"gpt-4o-mini\"\r\n    api_key env.OPENAI_API_KEY\r\n    temperature 0\r\n  }\r\n}\r\n\r\nclient<llm> CustomSonnet {\r\n  provider anthropic\r\n  options {\r\n    model \"claude-3-5-sonnet-20241022\"\r\n    api_key env.ANTHROPIC_API_KEY\r\n  }\r\n}\r\n\r\n\r\nclient<llm> CustomHaiku {\r\n  provider anthropic\r\n  retry_policy Constant\r\n  options {\r\n    model \"claude-3-haiku-20240307\"\r\n    api_key env.ANTHROPIC_API_KEY\r\n  }\r\n}\r\n\r\n// https://docs.boundaryml.com/docs/snippets/clients/round-robin\r\nclient<llm> CustomFast {\r\n  provider round-robin\r\n  options {\r\n    // This will alternate between the two clients\r\n    strategy [CustomGPT4oMini, CustomHaiku]\r\n  }\r\n}\r\n\r\n// https://docs.boundaryml.com/docs/snippets/clients/fallback\r\nclient<llm> OpenaiFallback {\r\n  provider fallback\r\n  options {\r\n    // This will try the clients in order until one succeeds\r\n    strategy [CustomGPT4oMini, CustomGPT4oMini]\r\n  }\r\n}\r\n\r\n// https://docs.boundaryml.com/docs/snippets/clients/retry\r\nretry_policy Constant {\r\n  max_retries 3\r\n  // Strategy is optional\r\n  strategy {\r\n    type constant_delay\r\n    delay_ms 200\r\n  }\r\n}\r\n\r\nretry_policy Exponential {\r\n  max_retries 2\r\n  // Strategy is optional\r\n  strategy {\r\n    type exponential_backoff\r\n    delay_ms 300\r\n    multiplier 1.5\r\n    max_delay_ms 10000\r\n  }\r\n}",
    "generators.baml": "// This helps use auto generate libraries you can use in the language of\n// your choice. You can have multiple generators if you use multiple languages.\n// Just ensure that the output_dir is different for each generator.\ngenerator target {\n    // Valid values: \"python/pydantic\", \"typescript\", \"ruby/sorbet\", \"rest/openapi\"\n    output_type \"python/pydantic\"\n\n    // Where the generated code will be saved (relative to baml_src/)\n    output_dir \"../\"\n\n    // The version of the BAML package you have installed (e.g. same version as your baml-py or @boundaryml/baml).\n    // The BAML VSCode extension version should also match this version.\n    version \"0.88.0\"\n\n    // Valid values: \"sync\", \"async\"\n    // This controls what `b.FunctionName()` will be (sync or async).\n    default_client_mode sync\n}\n",
    "planner.baml": "// Defining math tool classes\r\nclass MathTool {\r\n  name string\r\n  description string\r\n}\r\n\r\nclass ToolCall {\r\n  tool string\r\n  args float[]\r\n  description string\r\n}\r\n\r\nclass Plan {\r\n  calls ToolCall[]\r\n  explanation string\r\n}\r\n\r\n// Define the Planner function that will generate a plan of tool calls\r\nfunction GenerateMathPlan(instructions: string, tools: MathTool[]) -> Plan {\r\n  client CustomGPT4oMini // Using the same client as in resume.baml\r\n\r\n  prompt #\"\r\n    You are a planning assistant that takes natural language instructions and available tools,\r\n    and generates a plan of tool calls to fulfill the instructions.\r\n    \r\n    {{ ctx.output_format }}\r\n    \r\n    {{_.role(\"user\")}}\r\n    Available tools:\r\n    {{ tools }}\r\n    \r\n    Instructions:\r\n    {{ instructions }}\r\n    \r\n    Generate a plan using these tools. The plan should be a list of tool calls with proper arguments.\r\n    Each tool call should include which tool to use, what arguments to pass, and a brief description of what this step achieves.\r\n    Also include an overall explanation of the plan.\r\n\r\n    Format your response as a structured JSON object with this schema:\r\n    {\r\n      \"calls\": [\r\n        {\r\n          \"tool\": \"tool_name\",\r\n          \"args\": [number1, number2, ...],\r\n          \"description\": \"Description of what this call achieves\"\r\n        }\r\n      ],\r\n      \"explanation\": \"Overall explanation of the plan\"\r\n    }\r\n  \"#\r\n}\r\n\r\n// Test case for the planner with addition\r\ntest simple_math_plan {\r\n  functions [GenerateMathPlan]\r\n  args {\r\n    instructions \"add 42 and 58\"\r\n    tools [\r\n      {\r\n        name \"Sum\"\r\n        description \"Adds two numbers together\"\r\n      }\r\n    ]\r\n  }\r\n}\r\n\r\n// Test cases for the planner\r\ntest simple_addition_plan {\r\n  functions [GenerateMathPlan]\r\n  args {\r\n    instructions \"add 42 and 58\"\r\n    tools [\r\n      {\r\n        name \"Sum\"\r\n        description \"Adds two numbers together\"\r\n      }\r\n    ]\r\n  }\r\n}\r\n\r\ntest multi_step_calculation {\r\n  functions [GenerateMathPlan]\r\n  args {\r\n    instructions \"multiply 10 and 5, then subtract 15\"\r\n    tools [\r\n      {\r\n        name \"Multiply\"\r\n        description \"Multiplies two numbers together\"\r\n      },\r\n      {\r\n        name \"Subtract\"\r\n        description \"Subtracts second number from first\"\r\n      }\r\n    ]\r\n  }\r\n}\r\n",
    "resume.baml": "// Defining a data model.\r\nclass Resume {\r\n  name string\r\n  email string\r\n  experience Experience[]\r\n  skills string[]\r\n}\r\n\r\nclass Experience {\r\n  company string\r\n  role string\r\n  duration string\r\n  location string\r\n}\r\n\r\n// Create a function to extract the resume from a string.\r\nfunction ExtractResume(resume: string) -> Resume {\r\n  // Specify a client as provider/model-name\r\n  // you can use custom LLM params with a custom client name from clients.baml like \"client CustomHaiku\"\r\n  client CustomGPT4oMini // Set OPENAI_API_KEY to use this client.\r\n  prompt #\"\r\n    Extract from this content:\r\n    {{ ctx.output_format }}\r\n\r\n    {{_.role(\"user\")}}\r\n    {{ resume }}\r\n\r\n  \"#\r\n}\r\n\r\n\r\n\r\n// Test the function with a sample resume. Open the VSCode playground to run this.\r\ntest vaibhav_resume {\r\n  functions [ExtractResume]\r\n  args {\r\n    resume #\"\r\n      Rohit Shende\r\n      rohitshende020@gmail.com\r\n\r\n      Experience:\r\n      - Founder at BoundaryML\r\n      - CV Engineer at Google\r\n      - CV Engineer at Microsoft\r\n\r\n      Skills:\r\n      - Rust\r\n      - C++\r\n    \"#\r\n  }\r\n}\r\n",
}

def get_baml_files():
    return file_map